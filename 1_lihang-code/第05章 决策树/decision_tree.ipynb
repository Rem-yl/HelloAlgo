{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch05 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树学习的本质是从训练数据集中归纳出一组分类规则    \n",
    "决策树学习的损失函数通常是正则化的极大似然函数，学习策略是以损失函数为目标函数的最小化。    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果利用一个特征进行分类的结果与随机分类的结果没有很大差别,则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。    \n",
    "通常特征选择的准则是**信息增益**或**信息增益比**            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**熵**的定义:           \n",
    "$$\n",
    "p(X = x_i) = p_i    \\\\\n",
    "H(X) = -\\sum_{i=1}^n p_i log p_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**条件熵**的定义:       \n",
    "$$\n",
    "H(Y|X) = \\sum_{i=1}^n p_i H(Y|X=x_i) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益(information gain)表示得知特征X的信息而使得类Y的信息的不确定性减少的程度   \n",
    "特征X对训练数据集D的信息增益$g(D,X)$\n",
    "$$\n",
    "g(D, X) = H(D) - H(D|X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**信息增益算法**               \n",
    "输入: 训练数据集D和特征A    \n",
    "输出: 特征A对训练数据集D的信息增益$g(D,A)$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./img/gain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算书上的例题 5.2**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    年龄 有工作 有自己的房子 信贷情况 类别\n",
      "0   青年   否      否   一般  否\n",
      "1   青年   否      否    好  否\n",
      "2   青年   是      否    好  是\n",
      "3   青年   是      是   一般  是\n",
      "4   青年   否      否   一般  否\n",
      "5   中年   否      否   一般  否\n",
      "6   中年   否      否    好  否\n",
      "7   中年   是      是    好  是\n",
      "8   中年   否      是  非常好  是\n",
      "9   中年   否      是  非常好  是\n",
      "10  老年   否      是  非常好  是\n",
      "11  老年   否      是    好  是\n",
      "12  老年   是      否    好  是\n",
      "13  老年   是      否  非常好  是\n",
      "14  老年   否      否   一般  否\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "                ['青年', '否', '否', '好', '否'],\n",
    "                ['青年', '是', '否', '好', '是'],\n",
    "                ['青年', '是', '是', '一般', '是'],\n",
    "                ['青年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '好', '否'],\n",
    "                ['中年', '是', '是', '好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '好', '是'],\n",
    "                ['老年', '是', '否', '好', '是'],\n",
    "                ['老年', '是', '否', '非常好', '是'],\n",
    "                ['老年', '否', '否', '一般', '否'],\n",
    "                ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels\n",
    "\n",
    "datasets, labels = create_data()\n",
    "train_data = pd.DataFrame(datasets, columns=labels)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 定义熵计算公式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if (p == 0.0):\n",
    "        return 0\n",
    "\n",
    "    return - p * np.log2(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 定义计算经验熵公式**       \n",
    "根据数据集的类别将数据集$D$划分为不同的子集$D_1, D_2, \\dots, D_k$\n",
    "\n",
    "$$\n",
    "H(D) = sum(entropy(len(D_i) / len(D)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "def calc_ent(df:pd.DataFrame, feature_name: str):\n",
    "    res = 0.0\n",
    "    unique_label = np.unique(df[feature_name])\n",
    "    \n",
    "    for label in unique_label:\n",
    "        sub_df = df[df[feature_name]==label]\n",
    "        res += entropy(len(sub_df) / len(df))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(calc_ent(train_data, \"类别\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 计算信息增益**     \n",
    "给定特征`feature_name`, 先计算整个数据集的$H(D)$, 根据特征的取值将数据集$D$划分为不同的子集$D_1, D_2, \\dots$    \n",
    "\n",
    "$$\n",
    "H(D|A) = \\sum \\frac{len(D_i)}{len(D)} * calc\\_ent(D_i) \\\\\n",
    "g(D, A) = H(D) - H(D|A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain of 年龄: 0.08300749985576883\n",
      "info gain of 有工作: 0.32365019815155627\n",
      "info gain of 有自己的房子: 0.4199730940219749\n",
      "info gain of 信贷情况: 0.36298956253708536\n"
     ]
    }
   ],
   "source": [
    "def info_gain(df:pd.DataFrame, feature_name:str, label_name:str):\n",
    "    H_D_A = 0.0\n",
    "    H_D = calc_ent(df, label_name)\n",
    "    \n",
    "    unique_feature = np.unique(df[feature_name])\n",
    "    \n",
    "    for feature in unique_feature:\n",
    "        sub_df = df[df[feature_name]==feature]\n",
    "        H_D_A += len(sub_df) / len(df) * calc_ent(sub_df, label_name)\n",
    "    \n",
    "    return H_D - H_D_A\n",
    "\n",
    "feature_names = train_data.columns.to_list()[:-1]\n",
    "for feature_name in feature_names:\n",
    "    gain = info_gain(train_data, feature_name, \"类别\")\n",
    "    print(f\"info gain of {feature_name}: {gain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**信息增益比**  \n",
    "以信息增益作为划分训练数据集的特征,存在偏向于选择取值较多的特征的问 题。使用信息增益比(information gain ratio)可以对这一问题进行校正\n",
    "\n",
    "$$\n",
    "g_R(D, A) = g(D, A) / H_A(D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05237190142858302\n"
     ]
    }
   ],
   "source": [
    "feature_name = \"年龄\"\n",
    "label_name = \"类别\"\n",
    "gain = info_gain(train_data, feature_name, label_name)\n",
    "h_a_d = calc_ent(train_data, feature_name)\n",
    "print(gain / h_a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Node:\n",
    "    def __init__(self, feature=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "        self.child = {}\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.label is not None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.is_leaf():\n",
    "            return f\"Leaf({self.label})\"\n",
    "        return f\"Node({self.feature}, {self.child})\"\n",
    "    \n",
    "class ID3DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    def best_split(self, df: pd.DataFrame) -> str:\n",
    "        feature_names = df.columns.to_list()[:-1]\n",
    "        label_name = df.columns.to_list()[-1]\n",
    "        gain_map = {}\n",
    "        \n",
    "        for feature_name in feature_names:\n",
    "            gain = info_gain(df, feature_name, label_name)\n",
    "            gain_map[feature_name] = gain \n",
    "            \n",
    "        return max(gain_map, key=gain_map.get)\n",
    "        \n",
    "    def train(self, df : pd.DataFrame):\n",
    "        self.root = self.build_tree(df)\n",
    "    \n",
    "    def build_tree(self, df: pd.DataFrame) -> Optional[Node]:\n",
    "        col_names = df.columns.to_list()\n",
    "        feature_names = col_names[:-1]\n",
    "        label_name = col_names[-1]\n",
    "        df_y = df[label_name]\n",
    "        unique_y = np.unique(df_y)\n",
    "        \n",
    "        if len(unique_y) == 1: # 只有一个类别, 返回叶子节点\n",
    "            return Node(label=unique_y[0])\n",
    "            \n",
    "        if len(feature_names) == 0:\n",
    "            # 没有特征可以划分\n",
    "            return Node(label=df_y.mode())\n",
    "        \n",
    "        best_feature = self.best_split(df)\n",
    "        root = Node(feature=best_feature)\n",
    "        \n",
    "        unique_feature_value = np.unique(df[best_feature])\n",
    "        \n",
    "        for feature_value in unique_feature_value:\n",
    "            sub_df = df[df[best_feature] == feature_value].drop(columns=[best_feature])\n",
    "            root.child[feature_value] = self.build_tree(sub_df)\n",
    "\n",
    "        return root\n",
    "    \n",
    "    def predict(self, x):\n",
    "        node = self.root \n",
    "        \n",
    "        while not node.is_leaf():\n",
    "            value = x.get(node.feature)    # 获取样本在当前feature上的取值\n",
    "            if value in node.child:\n",
    "                node = node.child[value]\n",
    "            else:\n",
    "                return None \n",
    "        \n",
    "        return node.label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否 否\n",
      "否 否\n",
      "是 是\n",
      "是 是\n",
      "否 否\n",
      "否 否\n",
      "否 否\n",
      "是 是\n",
      "是 是\n",
      "是 是\n",
      "是 是\n",
      "是 是\n",
      "是 是\n",
      "是 是\n",
      "否 否\n"
     ]
    }
   ],
   "source": [
    "model = ID3DecisionTree()\n",
    "model.train(train_data)\n",
    "\n",
    "for _, data in train_data.iterrows():\n",
    "    x = data.iloc[:-1]\n",
    "    y = data.iloc[-1]\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    print(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实纵观决策树的生成代码, 重要的不过两个函数:   \n",
    "- best_split: 根据不同的指标得到数据集的最佳划分点, 将这个划分点作为根节点, 划分出来的子数据集作为子树生成使用      \n",
    "- build_tree: 确定边界条件; 根据best_split函数得到的划分点生成根节点以及递归调用build_tree生成子树      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations  # 启用新的类型提示解析\n",
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature: str = None, thr: float = None, left: Node = None, right: Node = None, value: float = None):\n",
    "        self.feature = feature\n",
    "        self.thr = thr\n",
    "        self.value = value\n",
    "        self.left: Node = left\n",
    "        self.right: Node = right\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "def gini(y: np.ndarray) -> float:\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / len(y)  # 计算每个类别的概率\n",
    "    return 1.0 - np.sum(probs ** 2)  # 计算基尼指数\n",
    "\n",
    "\n",
    "class CARTClassfier:\n",
    "    def __init__(self, min_sample: int = 2, max_depth: int = 3):\n",
    "        self.min_sample = min_sample\n",
    "        self.max_depth = max_depth\n",
    "        self.root: Node = None\n",
    "\n",
    "    def best_split(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\" 返回最佳分割的特征和特征值 \"\"\"\n",
    "        best_gini = np.inf\n",
    "        best_feature, best_thr = None, None\n",
    "        best_left, best_right = None, None\n",
    "\n",
    "        n_samples, n_feats = x.shape\n",
    "        for feat in range(n_feats):\n",
    "            thrs = np.unique(x[:, feat])    # 对特征值进行去重操作\n",
    "            for thr in thrs:\n",
    "                left_mask = x[:, feat] <= thr   # 小于当前阈值的划归左子树\n",
    "                right_mask = ~left_mask # 大于当前阈值的划归右子树\n",
    "\n",
    "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_gini = gini(y[left_mask])\n",
    "                right_gini = gini(y[right_mask])\n",
    "                final_gini = (np.sum(left_mask) * left_gini + np.sum(right_mask) * right_gini) / n_samples\n",
    "\n",
    "                if final_gini < best_gini:\n",
    "                    best_gini = final_gini\n",
    "                    best_feature, best_thr = feat, thr\n",
    "                    best_left, best_right = left_mask, right_mask\n",
    "\n",
    "        return (best_feature, best_thr, best_left, best_right)\n",
    "\n",
    "    def build_tree(self, x: np.ndarray, y: np.ndarray, depth=0):\n",
    "        if len(set(y)) == 1 or len(y) < self.min_sample or (self.max_depth and depth >= self.max_depth):\n",
    "            return Node(value=np.argmax(np.bincount(y)))    # 返回多数类别\n",
    "\n",
    "        feature, thr, left_mask, right_mask = self.best_split(x, y)\n",
    "        if feature == None:\n",
    "            return Node(value=np.argmax(np.bincount(y)))\n",
    "\n",
    "        left_tree = self.build_tree(x[left_mask], y[left_mask], depth+1)\n",
    "        right_tree = self.build_tree(x[right_mask], y[right_mask], depth+1)\n",
    "\n",
    "        return Node(feature=feature, thr=thr, left=left_tree, right=right_tree)\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        self.root = self.build_tree(x, y)\n",
    "\n",
    "    def predict(self, x: np.ndarray):\n",
    "        node = self.root\n",
    "\n",
    "        while not node.is_leaf():\n",
    "            if x[node.feature] <= node.thr:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "\n",
    "        return node.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

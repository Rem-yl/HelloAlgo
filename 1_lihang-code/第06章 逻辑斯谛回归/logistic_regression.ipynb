{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "## Logistic Regression 的梯度下降算法推导\n",
    "\n",
    "1. 逻辑回归模型\n",
    "\n",
    "逻辑回归（Logistic Regression）用于二分类任务，其模型为：\t\t\n",
    "$$\n",
    "y = \\sigma(z) = \\sigma(Xw + b)\n",
    "$$\n",
    "其中：\t\t\t\n",
    "\t•\t X  是  m $\\times$ n  的数据矩阵，每行是一个样本，每列是一个特征，\t\t\t\t\n",
    "\t•\t w  是  n $\\times$ 1  的权重向量，\t\t\t\t\n",
    "\t•\t b  是标量偏置，\t\t\t\t\n",
    "\t•\t $z = Xw + b$  是线性变换后的结果，\t\t\t\t\n",
    "\t•\t $\\sigma(z)$  是 Sigmoid 激活函数：\t\t\t\t\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "2. 损失函数\n",
    "\n",
    "逻辑回归使用 二元交叉熵损失（Binary Cross-Entropy Loss）, 等价于对参数进行极大似然估计\t\t\t\n",
    "$$\n",
    "L = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\t•\t y_i  是真实标签，取值  $\\{0,1\\}$ ，\t\t\n",
    "\t•\t $\\hat{y}_i = \\sigma(z_i)$  是预测值。\t\t\n",
    "\n",
    "3. 计算梯度\n",
    "\n",
    "对权重  $w$  求梯度\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}_i - y_i \\right) x_i\n",
    "$$\n",
    "\n",
    "用矩阵形式表示：\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{1}{m} X^T (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "对偏置 $ b$  求梯度\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)\n",
    "$$\n",
    "矩阵形式：\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "4. 梯度下降更新公式\n",
    "\n",
    "使用梯度下降法（Gradient Descent）更新参数：\n",
    "$$\n",
    "w \\leftarrow w - \\alpha \\frac{\\partial L}{\\partial w} \\\\\n",
    "\n",
    "\n",
    "b \\leftarrow b - \\alpha \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "其中：\n",
    "\t•\t $\\alpha $ 是学习率（learning rate）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def sigmoid(x: np.ndarray):\n",
    "    eps = 1e-8\n",
    "    return 1.0 / (1 + np.exp(-x) + eps)\n",
    "\n",
    "class LogisticResgression:\n",
    "    def __init__(self, in_dim: int, out_dim: int, lr: float = 0.1):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.lr = lr\n",
    "\n",
    "        self._init_param()\n",
    "\n",
    "    def __call__(self, x: np.ndarray):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def _init_param(self):\n",
    "        self.w = np.random.randn(self.in_dim, self.out_dim)\n",
    "        self.b = np.zeros((1, self.out_dim))\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "    def train(self, X: np.ndarray, y: np.ndarray):\n",
    "        for _ in range(20):\n",
    "            # 使用单样本进行更新\n",
    "            for x, y_true in zip(X, y):\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                y_pred = self.predict(x)\n",
    "                err = np.sum(y_pred - y_true)\n",
    "                grad_w = err * x.T\n",
    "                grad_b = err\n",
    "                self.w -= self.lr * grad_w\n",
    "                self.b -= self.lr * grad_b\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        output = self.forward(X)\n",
    "        y_pred = sigmoid(output)\n",
    "\n",
    "        return y_pred.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "\n",
    "    data = np.array(df.iloc[:10000, [0, 1, -1]])\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    y = np.array([1 if i == 1 else -1 for i in y])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.7\n"
     ]
    }
   ],
   "source": [
    "X, y = get_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "y_train = np.where(y_train == -1, 0, 1)\n",
    "y_test = np.where(y_test == -1, 0, 1)\n",
    "model = LogisticResgression(X_train.shape[1], 1)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "auc = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"auc: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
